{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading all the focal brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_brands.pickle', 'rb') as file:\n",
    "    focal_brands = pickle.load(file)\n",
    "\n",
    "focal_brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data for Local Reviews of all brands having social data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('brand_visit_local_reviews.pickle', 'rb') as file:\n",
    "    brand_visit_local_reviews = pickle.load(file)\n",
    "\n",
    "brand_visit_local_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the distance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_results = pd.read_csv('data/distance_results.csv')\n",
    "distance_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the focal brands data to extract first neighbor and second neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the list of all focal brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_brands_list = focal_brands['BRANDS'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting visit and local review dataset for each focal brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_brands_visit_local_reviews = brand_visit_local_reviews[brand_visit_local_reviews['Name'].isin(focal_brands_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_second_degree_neighbors(foc_df):\n",
    "    first_neighbors = []\n",
    "    second_neighbors = {}\n",
    "    \n",
    "    # Extracting all first degree neighbors\n",
    "    focal_brand_name = foc_df['Name'].iloc[0]\n",
    "    first_neighbors = distance_results[(distance_results['From_PLACEKEY'] == foc_df['PLACEKEY'].iloc[0]) & (distance_results['Distance_km']<=16.0934)]['To_PLACEKEY'].to_list()\n",
    "    \n",
    "    # Extracting all second degree Neighbors and saving them as dictionary for relevant first degree neighbors\n",
    "    for j in tqdm(range(len(first_neighbors))):\n",
    "        second_neighbors_temp = distance_results[(distance_results['From_PLACEKEY'] == first_neighbors[j]) & (distance_results['Distance_km']<=16.0934)]['To_PLACEKEY'].to_list()\n",
    "        second_neighbors_temp = [second_neib for second_neib in second_neighbors_temp if second_neib not in first_neighbors]\n",
    "        second_neighbors[first_neighbors[j]] = list(set(second_neighbors_temp))\n",
    "        \n",
    "    return pd.Series([focal_brand_name, first_neighbors, second_neighbors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_brands_first_second_degree_neighbors = None\n",
    "\n",
    "for i in range(len(focal_brands_list)):\n",
    "    print('Executing for Brand:', focal_brands_list[i])\n",
    "    \n",
    "    foc_df = focal_brands_visit_local_reviews[focal_brands_visit_local_reviews['Name'] == focal_brands_list[i]]\n",
    "    first_second_neib_df = foc_df.groupby(['PLACEKEY'])[['PLACEKEY', 'Name']].apply(extract_first_second_degree_neighbors)\n",
    "    \n",
    "    if i == 0: # For the very first time, store the dataframe. For any next iterations, just perform the concatenation\n",
    "        focal_brands_first_second_degree_neighbors = first_second_neib_df\n",
    "    else:\n",
    "        focal_brands_first_second_degree_neighbors = pd.concat([focal_brands_first_second_degree_neighbors, first_second_neib_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('focal_brands_first_second_degree_neighbors.pickle', 'wb') as file:\n",
    "    pickle.dump(focal_brands_first_second_degree_neighbors, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "business-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
