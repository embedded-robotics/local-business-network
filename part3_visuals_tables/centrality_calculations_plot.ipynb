{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying all the focal brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_brands = ['Sephora',\n",
    " 'ULTA Beauty',\n",
    " 'Olive Garden',\n",
    " 'The Cheesecake Factory',\n",
    " 'Target',\n",
    " 'Walmart',\n",
    " 'Anthropologie',\n",
    " \"Victoria's Secret\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the social brands catalog to get visits later for each store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_visits = pd.read_csv('../data/revision_visits_revenue_2019.csv')\n",
    "brands_visits['brand_standard'] = brands_visits['brand'].apply(lambda x: x.strip().lower()) # For comparison with catalog.tsv\n",
    "brands_visits['date'] = brands_visits['date'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d').date())\n",
    "brands_visits = brands_visits.rename(columns={'brand': 'brand_visitation'})\n",
    "brands_visits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Travel Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/travel_time.pkl', 'rb') as file:\n",
    "    travel_time_dict = pickle.load(file)\n",
    "    \n",
    "travel_time_keys = list(travel_time_dict.keys())\n",
    "from_keys = [key[0] for key in travel_time_keys]\n",
    "to_keys = [key[1] for key in travel_time_keys]\n",
    "time_minutes = list(travel_time_dict.values())\n",
    "time_minutes = [int(time_inst.split(' ')[0]) for time_inst in time_minutes]\n",
    "\n",
    "travel_time = pd.DataFrame({'From_PLACEKEY': from_keys, 'To_PLACEKEY': to_keys, 'Time_mins': time_minutes})\n",
    "travel_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the statistics of the specific focal brand using the results of Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = focal_brands[1]\n",
    "focal_brand_path = os.path.join('../part2_r_statistics', brand)\n",
    "focal_brand_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading all the neighboring brands results for the selected focal brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(focal_brand_path)\n",
    "result_file_list = [file for file in file_list if file.find('_result') != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "for result_file in result_file_list:\n",
    "    result_file_path = os.path.join(focal_brand_path, result_file)\n",
    "    tmp_res_df = pd.read_csv(result_file_path, skiprows=1, float_precision=\"round_trip\")\n",
    "    # Removing all the records for ols and m_olsExp\n",
    "    if 'filename' in tmp_res_df['filename'].tolist(): #Wrong input\n",
    "        continue\n",
    "    result_df = pd.concat([result_df, tmp_res_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df[~result_df['type'].isin(['ols', 'm_olsExp'])].reset_index(drop=True)\n",
    "result_df = result_df.replace('FALSE', False).replace('False', False)\n",
    "# result_df.iloc[:,3:] = result_df.iloc[:,3:].astype('float64', copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(result_df['filename'].value_counts() == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(result_df['filename'].value_counts() == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(result_df['filename'].value_counts() == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(result_df['filename'].value_counts() == 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only getting those brands who have values for all the four models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_list = result_df['filename'].value_counts()\n",
    "valid_brands = count_list[count_list == 4].index.to_list() # having the values of all the four models\n",
    "len(valid_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df[result_df['filename'].isin(valid_brands)]\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the significant neighboring brands whose p-values for all the models are significant (<0.05) i.e., X_Pr(>|t|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_brands_pvalue(brand_pvalue):\n",
    "    pvalues = brand_pvalue.values\n",
    "    \n",
    "    if (pvalues[0] < 0.05) and (pvalues[1] < 0.05) and (pvalues[2] < 0.05) and (pvalues[3] < 0.05):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_brands = result_df.groupby('filename')['X_Pr(>|t|)'].apply(filter_brands_pvalue)\n",
    "significant_brands_list = significant_brands [significant_brands == True].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_brands_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing the calculations for WIC and WIBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly Calculating the Inverse and Inverse-Exp of the Time_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_time['Time_mins_inv'] = 1/travel_time['Time_mins']\n",
    "travel_time['Time_mins_inv_exp'] = 1/np.exp(travel_time['Time_mins'])\n",
    "travel_time = travel_time.rename(columns={'From_PLACEKEY': 'Focal_Stores', 'To_PLACEKEY': 'Neib_Stores'})\n",
    "travel_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extracting all the stores of the significant brands and focal store\n",
    "2. Calculating the Average Visits of each store to be used as average sales\n",
    "3. Dropping all the duplicate rows to have a clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_visits_focal_sig_neib = brands_visits[(brands_visits['brand_visitation'].isin(significant_brands_list)) | (brands_visits['brand_visitation']==brand)]\n",
    "brands_visits_focal_sig_neib.loc[:,'avg_visits'] = brands_visits_focal_sig_neib.groupby('PLACEKEY')['visits_by_day'].transform('mean')\n",
    "brands_visits_focal_sig_neib = brands_visits_focal_sig_neib.drop(columns=['date', 'visits_by_day', 'spend_by_day'])\n",
    "brands_visits_focal_sig_neib = brands_visits_focal_sig_neib.drop_duplicates().reset_index(drop=True)\n",
    "brands_visits_focal_sig_neib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the time_mins with all the focal stores belonging to brand under consideration, and all of the significant brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_stores = brands_visits_focal_sig_neib[brands_visits_focal_sig_neib['brand_visitation'] == brand]['PLACEKEY'].unique().tolist()\n",
    "sig_neib_stores = brands_visits_focal_sig_neib[brands_visits_focal_sig_neib['brand_visitation'].isin(significant_brands_list)]['PLACEKEY'].unique().tolist()\n",
    "travel_time_filtered = travel_time[(travel_time['Focal_Stores'].isin(focal_stores)) & (travel_time['Neib_Stores'].isin(sig_neib_stores))]\n",
    "travel_time_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging by Focal Stores to get the average visits of the focal stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_time_filtered = pd.merge(left=travel_time_filtered, right=brands_visits_focal_sig_neib, how='left', left_on='Focal_Stores', right_on='PLACEKEY')\n",
    "travel_time_filtered = travel_time_filtered.drop(columns=['PLACEKEY', 'brand_standard']).rename(columns={'brand_visitation':'Foc_Brand', 'lat':'Foc_lat', 'lon':'Foc_lon', 'avg_visits': 'Foc_avg_visits'})\n",
    "travel_time_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging by Neighboring Stores to get the average visits of the neighboring stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_time_filtered = pd.merge(left=travel_time_filtered, right=brands_visits_focal_sig_neib, how='left', left_on='Neib_Stores', right_on='PLACEKEY')\n",
    "travel_time_filtered = travel_time_filtered.drop(columns=['PLACEKEY','lat', 'lon', 'brand_standard']).rename(columns={'brand_visitation':'Neib_Brand', 'avg_visits': 'Neib_avg_visits'})\n",
    "travel_time_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Neib Centrality Calculations by taking each neighboring brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centrality_calc_reviews(group_df):\n",
    "    neib_brand = group_df.name\n",
    "    neib_result_df = result_df [result_df['filename'] == neib_brand]\n",
    "    \n",
    "    dist_l = group_df['Time_mins_inv'].values\n",
    "    dist2_l = group_df['Time_mins_inv_exp'].values\n",
    "    average_sales = group_df['Neib_avg_visits'].values\n",
    "    est_reviews = neib_result_df[neib_result_df['type'] == 'fe_reviews_reviews']['X_Estimate'].values[0]\n",
    "    est_reviews_exp = neib_result_df[neib_result_df['type'] == 'fe_exp_reviews_reviews']['X_Estimate'].values[0]\n",
    "\n",
    "    weighted_influence = np.sum(np.array(dist_l).dot(np.array(average_sales))*float(est_reviews))\n",
    "    weighted_influence_exp = np.sum(np.array(dist2_l).dot(np.array(average_sales))*float(est_reviews_exp))\n",
    "    influence = np.sum(np.array(dist_l)*float(est_reviews))\n",
    "    influence_exp = np.sum(np.array(dist2_l)*float(est_reviews_exp))\n",
    "    weighted_no_influence = np.sum(np.array(dist_l).dot(np.array(average_sales)))\n",
    "    no_influence = np.sum(np.array(dist_l))\n",
    "    avg_visits = np.mean(average_sales)\n",
    "    dist_inv = np.mean([1.0 / d for d in np.array(dist_l)])\n",
    "    num_stores = group_df['Neib_Stores'].nunique()\n",
    "    \n",
    "    return pd.Series({'weighted_influence': weighted_influence, 'weighted_influence_exp': weighted_influence_exp, 'influence': influence, 'influence_exp':influence_exp,\n",
    "                      'weighted_no_influence': weighted_no_influence, 'no_influence': no_influence, 'avg_visits':avg_visits, 'dist_inv': dist_inv, 'num_stores': num_stores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neib_centrality_reviews = travel_time_filtered.groupby('Neib_Brand')[['Time_mins_inv', 'Time_mins_inv_exp', 'Neib_avg_visits', 'Neib_Stores']].apply(centrality_calc_reviews).reset_index()\n",
    "neib_centrality_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centrality_calc_visits(group_df):\n",
    "    neib_brand = group_df.name\n",
    "    neib_result_df = result_df [result_df['filename'] == neib_brand]\n",
    "    \n",
    "    dist_l = group_df['Time_mins_inv'].values\n",
    "    dist2_l = group_df['Time_mins_inv_exp'].values\n",
    "    average_sales = group_df['Neib_avg_visits'].values\n",
    "    est_visits = neib_result_df[neib_result_df['type'] == 'fe_reviews_visits']['X_Estimate'].values[0]\n",
    "    est_visits_exp = neib_result_df[neib_result_df['type'] == 'fe_exp_reviews_visits']['X_Estimate'].values[0]\n",
    "\n",
    "    weighted_influence = np.sum(np.array(dist_l).dot(np.array(average_sales))*float(est_visits))\n",
    "    weighted_influence_exp = np.sum(np.array(dist2_l).dot(np.array(average_sales))*float(est_visits_exp))\n",
    "    influence = np.sum(np.array(dist_l)*float(est_visits))\n",
    "    influence_exp = np.sum(np.array(dist2_l)*float(est_visits_exp))\n",
    "    weighted_no_influence = np.sum(np.array(dist_l).dot(np.array(average_sales)))\n",
    "    no_influence = np.sum(np.array(dist_l))\n",
    "    avg_visits = np.mean(average_sales)\n",
    "    dist_inv = np.mean([1.0 / d for d in np.array(dist_l)])\n",
    "    num_stores = group_df['Neib_Stores'].nunique()\n",
    "    \n",
    "    return pd.Series({'weighted_influence': weighted_influence, 'weighted_influence_exp': weighted_influence_exp, 'influence': influence, 'influence_exp':influence_exp,\n",
    "                      'weighted_no_influence': weighted_no_influence, 'no_influence': no_influence, 'avg_visits':avg_visits, 'dist_inv': dist_inv, 'num_stores': num_stores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neib_centrality_visits = travel_time_filtered.groupby('Neib_Brand')[['Time_mins_inv', 'Time_mins_inv_exp', 'Neib_avg_visits', 'Neib_Stores']].apply(centrality_calc_visits).reset_index()\n",
    "neib_centrality_visits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Inner Centrality Calculations by taking each focal store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_centrality_calc_reviews(group_df):\n",
    "        \n",
    "    dist_l = group_df['Time_mins_inv'].values\n",
    "    dist2_l = group_df['Time_mins_inv_exp'].values\n",
    "    average_sales = group_df['Neib_avg_visits'].values\n",
    "    \n",
    "    est_reviews = []\n",
    "    est_exp_reviews = []\n",
    "    neib_brand_list = group_df['Neib_Brand'].values.tolist()\n",
    "    for neib_brand in neib_brand_list:\n",
    "        neib_result_df = result_df[result_df['filename'] == neib_brand]\n",
    "        est_reviews.append(neib_result_df[neib_result_df['type'] == 'fe_reviews_reviews']['X_Estimate'].values[0])\n",
    "        est_exp_reviews.append(neib_result_df[neib_result_df['type'] == 'fe_exp_reviews_reviews']['X_Estimate'].values[0])\n",
    "\n",
    "    weighted_influence = np.sum(np.array(est_reviews) * np.array(dist_l) * np.array(average_sales))\n",
    "    weighted_influence_exp = np.sum(np.array(est_exp_reviews) * np.array(dist2_l) * np.array(average_sales))\n",
    "    influence = np.sum(np.array(est_reviews) * np.array(dist_l))\n",
    "    influence_exp = np.sum(np.array(est_exp_reviews) * np.array(dist2_l))\n",
    "    dist_inv = np.mean([1.0 / d for d in np.array(dist_l)])\n",
    "    avg_visits = np.mean(average_sales)\n",
    "    weighted_no_influence = np.sum(np.array(dist_l) * np.array(average_sales))\n",
    "    no_influence = np.sum(np.array(dist_l))\n",
    "    num_stores = group_df['Neib_Stores'].nunique()\n",
    "    focal_lat = group_df['Foc_lat'].values[0]\n",
    "    focal_lon = group_df['Foc_lon'].values[0]    \n",
    "\n",
    "\n",
    "    return pd.Series({'weighted_influence': weighted_influence, 'weighted_influence_exp': weighted_influence_exp, 'influence': influence, 'influence_exp': influence_exp,\n",
    "                      'weighted_no_influence': weighted_no_influence, 'no_influence': no_influence, 'avg_visits':avg_visits, 'dist_inv': dist_inv, 'num_stores': num_stores,\n",
    "                      'focal_lat': focal_lat, 'focal_lon': focal_lon})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_centrality_reviews = travel_time_filtered.groupby('Focal_Stores')[['Time_mins_inv', 'Time_mins_inv_exp', 'Neib_avg_visits', 'Neib_Brand', 'Neib_Stores', 'Foc_lat', 'Foc_lon']].apply(inner_centrality_calc_reviews).reset_index()\n",
    "inner_centrality_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_centrality_calc_visits(group_df):\n",
    "        \n",
    "    dist_l = group_df['Time_mins_inv'].values\n",
    "    dist2_l = group_df['Time_mins_inv_exp'].values\n",
    "    average_sales = group_df['Neib_avg_visits'].values\n",
    "    \n",
    "    est_visits = []\n",
    "    est_exp_visits = []\n",
    "    neib_brand_list = group_df['Neib_Brand'].values.tolist()\n",
    "    for neib_brand in neib_brand_list:\n",
    "        neib_result_df = result_df[result_df['filename'] == neib_brand]\n",
    "        est_visits.append(neib_result_df[neib_result_df['type'] == 'fe_reviews_visits']['X_Estimate'].values[0])\n",
    "        est_exp_visits.append(neib_result_df[neib_result_df['type'] == 'fe_exp_reviews_visits']['X_Estimate'].values[0])\n",
    "\n",
    "    weighted_influence = np.sum(np.array(est_visits) * np.array(dist_l) * np.array(average_sales))\n",
    "    weighted_influence_exp = np.sum(np.array(est_exp_visits) * np.array(dist2_l) * np.array(average_sales))\n",
    "    influence = np.sum(np.array(est_visits) * np.array(dist_l))\n",
    "    influence_exp = np.sum(np.array(est_exp_visits) * np.array(dist2_l))\n",
    "    dist_inv = np.mean([1.0 / d for d in np.array(dist_l)])\n",
    "    avg_visits = np.mean(average_sales)\n",
    "    weighted_no_influence = np.sum(np.array(dist_l) * np.array(average_sales))\n",
    "    no_influence = np.sum(np.array(dist_l))\n",
    "    num_stores = group_df['Neib_Stores'].nunique()\n",
    "    focal_lat = group_df['Foc_lat'].values[0]\n",
    "    focal_lon = group_df['Foc_lon'].values[0]    \n",
    "\n",
    "\n",
    "    return pd.Series({'weighted_influence': weighted_influence, 'weighted_influence_exp': weighted_influence_exp, 'influence': influence, 'influence_exp': influence_exp,\n",
    "                      'weighted_no_influence': weighted_no_influence, 'no_influence': no_influence, 'avg_visits':avg_visits, 'dist_inv': dist_inv, 'num_stores': num_stores,\n",
    "                      'focal_lat': focal_lat, 'focal_lon': focal_lon})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_centrality_visits = travel_time_filtered.groupby('Focal_Stores')[['Time_mins_inv', 'Time_mins_inv_exp', 'Neib_avg_visits', 'Neib_Brand', 'Neib_Stores', 'Foc_lat', 'Foc_lon']].apply(inner_centrality_calc_visits).reset_index()\n",
    "inner_centrality_visits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the visits for all the businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Reviews Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_all_business_pure_reviews = travel_time_filtered\n",
    "visits_all_business_pure_reviews['Neib_est_review'] = visits_all_business_pure_reviews['Neib_Brand'].apply(lambda x: result_df[(result_df['filename'] == x) & (result_df['type'] == 'fe_reviews_reviews')]['X_Estimate'].values[0])\n",
    "visits_all_business_pure_reviews['Neib_est_exp_review'] = visits_all_business_pure_reviews['Neib_Brand'].apply(lambda x: result_df[(result_df['filename'] == x) & (result_df['type'] == 'fe_exp_reviews_reviews')]['X_Estimate'].values[0])\n",
    "visits_all_business_pure_reviews['num_inf'] = visits_all_business_pure_reviews['Neib_est_review'] * visits_all_business_pure_reviews['Time_mins_inv']\n",
    "visits_all_business_pure_reviews['num_inf_exp'] = visits_all_business_pure_reviews['Neib_est_exp_review'] * visits_all_business_pure_reviews['Time_mins_inv_exp']\n",
    "visits_all_business_pure_reviews['num_inf_visits'] = visits_all_business_pure_reviews['Neib_est_review'] * visits_all_business_pure_reviews['Time_mins_inv'] * visits_all_business_pure_reviews['Neib_avg_visits']\n",
    "visits_all_business_pure_reviews['num_inf_visits_exp'] = visits_all_business_pure_reviews['Neib_est_exp_review'] * visits_all_business_pure_reviews['Time_mins_inv_exp'] * visits_all_business_pure_reviews['Neib_avg_visits']\n",
    "visits_all_business_pure_reviews['weighted_visits'] = visits_all_business_pure_reviews['Time_mins_inv'] * visits_all_business_pure_reviews['Neib_avg_visits']\n",
    "visits_all_business_pure_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_all_business_pure_reviews = visits_all_business_pure_reviews.sort_values('num_inf_visits', ascending=False)\n",
    "\n",
    "ranked_dic_reviews = visits_all_business_pure_reviews.groupby('Neib_Brand').agg(distance=('Time_mins', 'mean'),\n",
    "                                                   avg_visits=('Neib_avg_visits', 'sum'),\n",
    "                                                   weighted_visits=('weighted_visits', 'sum'),\n",
    "                                                   num_inf = ('num_inf', 'sum'),\n",
    "                                                   num_inf_visits = ('num_inf_visits','sum')\n",
    "                                                )\n",
    "ranked_dic_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_all_business_pure_reviews = visits_all_business_pure_reviews.sort_values('num_inf_visits_exp', ascending=False)\n",
    "\n",
    "ranked_dic_reviews_exp = visits_all_business_pure_reviews.groupby('Neib_Brand').agg(distance=('Time_mins', 'mean'),\n",
    "                                                   avg_visits=('Neib_avg_visits', 'sum'),\n",
    "                                                   weighted_visits=('weighted_visits', 'sum'),\n",
    "                                                   num_inf = ('num_inf_exp', 'sum'),\n",
    "                                                   num_inf_visits = ('num_inf_visits_exp','sum')\n",
    "                                                )\n",
    "ranked_dic_reviews_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Visits Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_all_business_pure_visits = travel_time_filtered\n",
    "visits_all_business_pure_visits['Neib_est_visits'] = visits_all_business_pure_visits['Neib_Brand'].apply(lambda x: result_df[(result_df['filename'] == x) & (result_df['type'] == 'fe_reviews_visits')]['X_Estimate'].values[0])\n",
    "visits_all_business_pure_visits['Neib_est_exp_visits'] = visits_all_business_pure_visits['Neib_Brand'].apply(lambda x: result_df[(result_df['filename'] == x) & (result_df['type'] == 'fe_exp_reviews_visits')]['X_Estimate'].values[0])\n",
    "visits_all_business_pure_visits['num_inf'] = visits_all_business_pure_visits['Neib_est_visits'] * visits_all_business_pure_visits['Time_mins_inv']\n",
    "visits_all_business_pure_visits['num_inf_exp'] = visits_all_business_pure_visits['Neib_est_exp_visits'] * visits_all_business_pure_visits['Time_mins_inv_exp']\n",
    "visits_all_business_pure_visits['num_inf_visits'] = visits_all_business_pure_visits['Neib_est_visits'] * visits_all_business_pure_visits['Time_mins_inv'] * visits_all_business_pure_visits['Neib_avg_visits']\n",
    "visits_all_business_pure_visits['num_inf_visits_exp'] = visits_all_business_pure_visits['Neib_est_exp_visits'] * visits_all_business_pure_visits['Time_mins_inv_exp'] * visits_all_business_pure_visits['Neib_avg_visits']\n",
    "visits_all_business_pure_visits['weighted_visits'] = visits_all_business_pure_visits['Time_mins_inv'] * visits_all_business_pure_visits['Neib_avg_visits']\n",
    "visits_all_business_pure_visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_all_business_pure_visits = visits_all_business_pure_visits.sort_values('num_inf_visits', ascending=False)\n",
    "\n",
    "ranked_dic_visits = visits_all_business_pure_visits.groupby('Neib_Brand').agg(distance=('Time_mins', 'mean'),\n",
    "                                                   avg_visits=('Neib_avg_visits', 'sum'),\n",
    "                                                   weighted_visits=('weighted_visits', 'sum'),\n",
    "                                                   num_inf = ('num_inf', 'sum'),\n",
    "                                                   num_inf_visits = ('num_inf_visits','sum')\n",
    "                                                )\n",
    "ranked_dic_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_all_business_pure_visits = visits_all_business_pure_visits.sort_values('num_inf_visits_exp', ascending=False)\n",
    "\n",
    "ranked_dic_visits_exp = visits_all_business_pure_visits.groupby('Neib_Brand').agg(distance=('Time_mins', 'mean'),\n",
    "                                                   avg_visits=('Neib_avg_visits', 'sum'),\n",
    "                                                   weighted_visits=('weighted_visits', 'sum'),\n",
    "                                                   num_inf = ('num_inf_exp', 'sum'),\n",
    "                                                   num_inf_visits = ('num_inf_visits_exp','sum')\n",
    "                                                )\n",
    "ranked_dic_visits_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 Web Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the folder to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join('example1_web_design', brand)\n",
    "os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "top_selected_w = neib_centrality_reviews.sort_values('weighted_influence', ascending =False)[:k]['Neib_Brand'].values\n",
    "top_selected = neib_centrality_reviews.sort_values('influence', ascending =False)[:k]['Neib_Brand'].values\n",
    "most_avg_visits = ranked_dic_reviews.sort_values('avg_visits', ascending =False).index[:k].values\n",
    "closest_distance = ranked_dic_reviews.sort_values('distance', ascending = True).index[:k].values\n",
    "closest_weighted = ranked_dic_reviews.sort_values('weighted_visits', ascending =False).index[:k].values\n",
    "num_inf = ranked_dic_reviews.sort_values('num_inf', ascending = False).index[:k].values\n",
    "num_inf_visits = ranked_dic_reviews.sort_values('num_inf_visits', ascending =False).index[:k].values\n",
    "\n",
    "visits_rage = [0.0109, 0.0509] # mean is 3.09 #https://martech.org/report-cost-to-drive-store-visits-varies-widely-by-category-mobile-most-efficient-channel/\n",
    "exmple_1_web_design = []\n",
    "\n",
    "\n",
    "def compute_visits(selected, current_visits_rate):\n",
    "    sub_g = visits_all_business_pure_reviews[visits_all_business_pure_reviews.Neib_Brand.isin(list(selected))]    \n",
    "    return sub_g.num_inf_visits.sum() * current_visits_rate\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    top_cent_visits = compute_visits(top_selected, current_visits_rate)\n",
    "    top_w_cent_visits = compute_visits(top_selected_w, current_visits_rate)\n",
    "    random_selected = random.choices(visits_all_business_pure_reviews.Neib_Brand.unique(), k = k)\n",
    "    random_visits = compute_visits(random_selected, current_visits_rate)\n",
    "    most_avg_visits_inf = compute_visits(most_avg_visits, current_visits_rate)\n",
    "    closest_distance_inf = compute_visits(closest_distance, current_visits_rate)\n",
    "    closest_weighted_inf =compute_visits(closest_weighted, current_visits_rate)\n",
    "    exmple_1_web_design.append([top_cent_visits, top_w_cent_visits, random_visits, most_avg_visits_inf, closest_weighted_inf, closest_distance_inf])\n",
    "    \n",
    "exmple_1_web_design = pd.DataFrame(exmple_1_web_design, columns = ['top_cent_visits', 'top_w_cent_visits', 'random_visits', 'most_avg_visits_inf', 'closest_weighted_inf', \"closest_distance_inf\"])\n",
    "\n",
    "exmple_1_web_design.mean()\n",
    "exmple_1_web_design['type'] = 'example_1_web_design'\n",
    "exmple_1_web_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "DAY = 30 \n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "data = exmple_1_web_design\n",
    "data_sub = data.melt(value_vars = data.columns[:-1])\n",
    "data_sub['value'] = data_sub['value'].astype('float')\n",
    "\n",
    "data_sub['Increased visits'] = DAY * data_sub['value']\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Increased visits')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(6), ['MIC', 'WIC', 'random', 'avg visits', 'weighted visits', 'closest'], fontsize = 12, rotation = 30, fontweight = 'bold')\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'reviews.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "top_selected_w = neib_centrality_reviews.sort_values('weighted_influence_exp', ascending =False)[:k]['Neib_Brand'].values\n",
    "top_selected = neib_centrality_reviews.sort_values('influence_exp', ascending =False)[:k]['Neib_Brand'].values\n",
    "most_avg_visits = ranked_dic_reviews_exp.sort_values('avg_visits', ascending =False).index[:k].values\n",
    "closest_distance = ranked_dic_reviews_exp.sort_values('distance', ascending = True).index[:k].values\n",
    "closest_weighted = ranked_dic_reviews_exp.sort_values('weighted_visits', ascending =False).index[:k].values\n",
    "num_inf = ranked_dic_reviews_exp.sort_values('num_inf', ascending = False).index[:k].values\n",
    "num_inf_visits = ranked_dic_reviews_exp.sort_values('num_inf_visits', ascending =False).index[:k].values\n",
    "\n",
    "visits_rage = [0.0109, 0.0509] # mean is 3.09 #https://martech.org/report-cost-to-drive-store-visits-varies-widely-by-category-mobile-most-efficient-channel/\n",
    "exmple_1_web_design = []\n",
    "\n",
    "\n",
    "def compute_visits(selected, current_visits_rate):\n",
    "    sub_g = visits_all_business_pure_reviews[visits_all_business_pure_reviews.Neib_Brand.isin(list(selected))]    \n",
    "    return sub_g.num_inf_visits_exp.sum() * current_visits_rate\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    top_cent_visits = compute_visits(top_selected, current_visits_rate)\n",
    "    top_w_cent_visits = compute_visits(top_selected_w, current_visits_rate)\n",
    "    random_selected = random.choices(visits_all_business_pure_reviews.Neib_Brand.unique(), k = k)\n",
    "    random_visits = compute_visits(random_selected, current_visits_rate)\n",
    "    most_avg_visits_inf = compute_visits(most_avg_visits, current_visits_rate)\n",
    "    closest_distance_inf = compute_visits(closest_distance, current_visits_rate)\n",
    "    closest_weighted_inf =compute_visits(closest_weighted, current_visits_rate)\n",
    "    exmple_1_web_design.append([top_cent_visits, top_w_cent_visits, random_visits, most_avg_visits_inf, closest_weighted_inf, closest_distance_inf])\n",
    "    \n",
    "exmple_1_web_design = pd.DataFrame(exmple_1_web_design, columns = ['top_cent_visits', 'top_w_cent_visits', 'random_visits', 'most_avg_visits_inf', 'closest_weighted_inf', \"closest_distance_inf\"])\n",
    "\n",
    "exmple_1_web_design.mean()\n",
    "exmple_1_web_design['type'] = 'example_1_web_design'\n",
    "exmple_1_web_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "DAY = 30 \n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "data = exmple_1_web_design\n",
    "data_sub = data.melt(value_vars = data.columns[:-1])\n",
    "data_sub['value'] = data_sub['value'].astype('float')\n",
    "\n",
    "data_sub['Increased visits'] = DAY * data_sub['value']\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Increased visits')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(6), ['MIC', 'WIC', 'random', 'avg visits', 'weighted visits', 'closest'], fontsize = 12, rotation = 30, fontweight = 'bold')\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'reviews_exp.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "top_selected_w = neib_centrality_visits.sort_values('weighted_influence', ascending =False)[:k]['Neib_Brand'].values\n",
    "top_selected = neib_centrality_visits.sort_values('influence', ascending =False)[:k]['Neib_Brand'].values\n",
    "most_avg_visits = ranked_dic_visits.sort_values('avg_visits', ascending =False).index[:k].values\n",
    "closest_distance = ranked_dic_visits.sort_values('distance', ascending = True).index[:k].values\n",
    "closest_weighted = ranked_dic_visits.sort_values('weighted_visits', ascending =False).index[:k].values\n",
    "num_inf = ranked_dic_visits.sort_values('num_inf', ascending = False).index[:k].values\n",
    "num_inf_visits = ranked_dic_visits.sort_values('num_inf_visits', ascending =False).index[:k].values\n",
    "\n",
    "visits_rage = [0.0109, 0.0509] # mean is 3.09 #https://martech.org/report-cost-to-drive-store-visits-varies-widely-by-category-mobile-most-efficient-channel/\n",
    "exmple_1_web_design = []\n",
    "\n",
    "\n",
    "def compute_visits(selected, current_visits_rate):\n",
    "    sub_g = visits_all_business_pure_visits[visits_all_business_pure_visits.Neib_Brand.isin(list(selected))]    \n",
    "    return sub_g.num_inf_visits.sum() * current_visits_rate\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    top_cent_visits = compute_visits(top_selected, current_visits_rate)\n",
    "    top_w_cent_visits = compute_visits(top_selected_w, current_visits_rate)\n",
    "    random_selected = random.choices(visits_all_business_pure_visits.Neib_Brand.unique(), k = k)\n",
    "    random_visits = compute_visits(random_selected, current_visits_rate)\n",
    "    most_avg_visits_inf = compute_visits(most_avg_visits, current_visits_rate)\n",
    "    closest_distance_inf = compute_visits(closest_distance, current_visits_rate)\n",
    "    closest_weighted_inf =compute_visits(closest_weighted, current_visits_rate)\n",
    "    exmple_1_web_design.append([top_cent_visits, top_w_cent_visits, random_visits, most_avg_visits_inf, closest_weighted_inf, closest_distance_inf])\n",
    "    \n",
    "exmple_1_web_design = pd.DataFrame(exmple_1_web_design, columns = ['top_cent_visits', 'top_w_cent_visits', 'random_visits', 'most_avg_visits_inf', 'closest_weighted_inf', \"closest_distance_inf\"])\n",
    "\n",
    "exmple_1_web_design.mean()\n",
    "exmple_1_web_design['type'] = 'example_1_web_design'\n",
    "exmple_1_web_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "DAY = 30 \n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "data = exmple_1_web_design\n",
    "data_sub = data.melt(value_vars = data.columns[:-1])\n",
    "data_sub['value'] = data_sub['value'].astype('float')\n",
    "\n",
    "data_sub['Increased visits'] = DAY * data_sub['value']\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Increased visits')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(6), ['MIC', 'WIC', 'random', 'avg visits', 'weighted visits', 'closest'], fontsize = 12, rotation = 30, fontweight = 'bold')\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'visits.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "top_selected_w = neib_centrality_visits.sort_values('weighted_influence_exp', ascending =False)[:k]['Neib_Brand'].values\n",
    "top_selected = neib_centrality_visits.sort_values('influence_exp', ascending =False)[:k]['Neib_Brand'].values\n",
    "most_avg_visits = ranked_dic_visits_exp.sort_values('avg_visits', ascending =False).index[:k].values\n",
    "closest_distance = ranked_dic_visits_exp.sort_values('distance', ascending = True).index[:k].values\n",
    "closest_weighted = ranked_dic_visits_exp.sort_values('weighted_visits', ascending =False).index[:k].values\n",
    "num_inf = ranked_dic_visits_exp.sort_values('num_inf', ascending = False).index[:k].values\n",
    "num_inf_visits = ranked_dic_visits_exp.sort_values('num_inf_visits', ascending =False).index[:k].values\n",
    "\n",
    "visits_rage = [0.0109, 0.0509] # mean is 3.09 #https://martech.org/report-cost-to-drive-store-visits-varies-widely-by-category-mobile-most-efficient-channel/\n",
    "exmple_1_web_design = []\n",
    "\n",
    "\n",
    "def compute_visits(selected, current_visits_rate):\n",
    "    sub_g = visits_all_business_pure_visits[visits_all_business_pure_visits.Neib_Brand.isin(list(selected))]    \n",
    "    return sub_g.num_inf_visits_exp.sum() * current_visits_rate\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    top_cent_visits = compute_visits(top_selected, current_visits_rate)\n",
    "    top_w_cent_visits = compute_visits(top_selected_w, current_visits_rate)\n",
    "    random_selected = random.choices(visits_all_business_pure_visits.Neib_Brand.unique(), k = k)\n",
    "    random_visits = compute_visits(random_selected, current_visits_rate)\n",
    "    most_avg_visits_inf = compute_visits(most_avg_visits, current_visits_rate)\n",
    "    closest_distance_inf = compute_visits(closest_distance, current_visits_rate)\n",
    "    closest_weighted_inf =compute_visits(closest_weighted, current_visits_rate)\n",
    "    exmple_1_web_design.append([top_cent_visits, top_w_cent_visits, random_visits, most_avg_visits_inf, closest_weighted_inf, closest_distance_inf])\n",
    "    \n",
    "exmple_1_web_design = pd.DataFrame(exmple_1_web_design, columns = ['top_cent_visits', 'top_w_cent_visits', 'random_visits', 'most_avg_visits_inf', 'closest_weighted_inf', \"closest_distance_inf\"])\n",
    "\n",
    "exmple_1_web_design.mean()\n",
    "exmple_1_web_design['type'] = 'example_1_web_design'\n",
    "exmple_1_web_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "DAY = 30 \n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "data = exmple_1_web_design\n",
    "data_sub = data.melt(value_vars = data.columns[:-1])\n",
    "data_sub['value'] = data_sub['value'].astype('float')\n",
    "\n",
    "data_sub['Increased visits'] = DAY * data_sub['value']\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Increased visits')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(6), ['MIC', 'WIC', 'random', 'avg visits', 'weighted visits', 'closest'], fontsize = 12, rotation = 30, fontweight = 'bold')\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'visits_exp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 Choose Partner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the folder to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join('example2_choose_partner', brand)\n",
    "os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_rage = [0.0203, 0.0603]#[0.1, 0.2]\n",
    "k = 1\n",
    "\n",
    "top_selected_w = neib_centrality_reviews.sort_values('weighted_influence', ascending =False)[:k]['Neib_Brand'].values\n",
    "top_selected = neib_centrality_reviews.sort_values('influence', ascending =False)[:k]['Neib_Brand'].values\n",
    "most_avg_visits = ranked_dic_reviews.sort_values('avg_visits', ascending =False).index[:k].values\n",
    "closest_distance = ranked_dic_reviews.sort_values('distance', ascending = True).index[:k].values\n",
    "closest_weighted = ranked_dic_reviews.sort_values('weighted_visits', ascending =False).index[:k].values\n",
    "\n",
    "example_2_partner_choice = []\n",
    "\n",
    "def compute_visits(selected, current_visits_rate):\n",
    "    sub_g = visits_all_business_pure_reviews[visits_all_business_pure_reviews.Neib_Brand.isin(list(selected))]    \n",
    "    return sub_g.num_inf_visits.sum() * current_visits_rate\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    top_cent_visits = compute_visits(top_selected, current_visits_rate)\n",
    "    top_w_cent_visits = compute_visits(top_selected_w, current_visits_rate)\n",
    "    random_selected = random.choices(visits_all_business_pure_reviews.Neib_Brand.unique(), k = k)\n",
    "    random_visits = compute_visits(random_selected, current_visits_rate)\n",
    "    most_avg_visits_inf = compute_visits(most_avg_visits, current_visits_rate)\n",
    "    closest_distance_inf = compute_visits(closest_distance, current_visits_rate)\n",
    "    closest_weighted_inf =compute_visits(closest_weighted, current_visits_rate)\n",
    "    example_2_partner_choice.append([top_cent_visits, top_w_cent_visits, random_visits, most_avg_visits_inf, closest_weighted_inf, closest_distance_inf])\n",
    "\n",
    "\n",
    "example_2_partner_choice = pd.DataFrame(example_2_partner_choice, columns = ['top_cent_visits', 'top_w_cent_visits', 'random_visits', 'most_avg_visits_inf', 'closest_weighted_inf', \"closest_distance_inf\"])\n",
    "example_2_partner_choice.mean()\n",
    "example_2_partner_choice['type'] = 'example_2_partner_choice'\n",
    "example_2_partner_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "DAY = 30 \n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "data = example_2_partner_choice\n",
    "data_sub = data.melt(value_vars = data.columns[:-1])\n",
    "data_sub['value'] = data_sub['value'].astype('float')\n",
    "\n",
    "data_sub['Increased visits'] = DAY * data_sub['value']#%/ 3200 * 100\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Increased visits')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(6), ['MIC', 'WIC', 'random', 'avg visits', 'weighted visits', 'closest'], fontsize = 12, rotation = 30, fontweight = 'bold')\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'reviews.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_rage = [0.0203, 0.0603]#[0.1, 0.2]\n",
    "k = 1\n",
    "\n",
    "top_selected_w = neib_centrality_reviews.sort_values('weighted_influence_exp', ascending =False)[:k]['Neib_Brand'].values\n",
    "top_selected = neib_centrality_reviews.sort_values('influence_exp', ascending =False)[:k]['Neib_Brand'].values\n",
    "most_avg_visits = ranked_dic_reviews_exp.sort_values('avg_visits', ascending =False).index[:k].values\n",
    "closest_distance = ranked_dic_reviews_exp.sort_values('distance', ascending = True).index[:k].values\n",
    "closest_weighted = ranked_dic_reviews_exp.sort_values('weighted_visits', ascending =False).index[:k].values\n",
    "\n",
    "example_2_partner_choice = []\n",
    "\n",
    "def compute_visits(selected, current_visits_rate):\n",
    "    sub_g = visits_all_business_pure_reviews[visits_all_business_pure_reviews.Neib_Brand.isin(list(selected))]    \n",
    "    return sub_g.num_inf_visits_exp.sum() * current_visits_rate\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    top_cent_visits = compute_visits(top_selected, current_visits_rate)\n",
    "    top_w_cent_visits = compute_visits(top_selected_w, current_visits_rate)\n",
    "    random_selected = random.choices(visits_all_business_pure_reviews.Neib_Brand.unique(), k = k)\n",
    "    random_visits = compute_visits(random_selected, current_visits_rate)\n",
    "    most_avg_visits_inf = compute_visits(most_avg_visits, current_visits_rate)\n",
    "    closest_distance_inf = compute_visits(closest_distance, current_visits_rate)\n",
    "    closest_weighted_inf =compute_visits(closest_weighted, current_visits_rate)\n",
    "    example_2_partner_choice.append([top_cent_visits, top_w_cent_visits, random_visits, most_avg_visits_inf, closest_weighted_inf, closest_distance_inf])\n",
    "\n",
    "\n",
    "example_2_partner_choice = pd.DataFrame(example_2_partner_choice, columns = ['top_cent_visits', 'top_w_cent_visits', 'random_visits', 'most_avg_visits_inf', 'closest_weighted_inf', \"closest_distance_inf\"])\n",
    "example_2_partner_choice.mean()\n",
    "example_2_partner_choice['type'] = 'example_2_partner_choice'\n",
    "example_2_partner_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "DAY = 30 \n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "data = example_2_partner_choice\n",
    "data_sub = data.melt(value_vars = data.columns[:-1])\n",
    "data_sub['value'] = data_sub['value'].astype('float')\n",
    "\n",
    "data_sub['Increased visits'] = DAY * data_sub['value']#%/ 3200 * 100\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Increased visits')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(6), ['MIC', 'WIC', 'random', 'avg visits', 'weighted visits', 'closest'], fontsize = 12, rotation = 30, fontweight = 'bold')\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'reviews_exp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_rage = [0.0203, 0.0603]#[0.1, 0.2]\n",
    "k = 1\n",
    "\n",
    "top_selected_w = neib_centrality_visits.sort_values('weighted_influence', ascending =False)[:k]['Neib_Brand'].values\n",
    "top_selected = neib_centrality_visits.sort_values('influence', ascending =False)[:k]['Neib_Brand'].values\n",
    "most_avg_visits = ranked_dic_visits.sort_values('avg_visits', ascending =False).index[:k].values\n",
    "closest_distance = ranked_dic_visits.sort_values('distance', ascending = True).index[:k].values\n",
    "closest_weighted = ranked_dic_visits.sort_values('weighted_visits', ascending =False).index[:k].values\n",
    "\n",
    "example_2_partner_choice = []\n",
    "\n",
    "def compute_visits(selected, current_visits_rate):\n",
    "    sub_g = visits_all_business_pure_visits[visits_all_business_pure_visits.Neib_Brand.isin(list(selected))]    \n",
    "    return sub_g.num_inf_visits.sum() * current_visits_rate\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    top_cent_visits = compute_visits(top_selected, current_visits_rate)\n",
    "    top_w_cent_visits = compute_visits(top_selected_w, current_visits_rate)\n",
    "    random_selected = random.choices(visits_all_business_pure_visits.Neib_Brand.unique(), k = k)\n",
    "    random_visits = compute_visits(random_selected, current_visits_rate)\n",
    "    most_avg_visits_inf = compute_visits(most_avg_visits, current_visits_rate)\n",
    "    closest_distance_inf = compute_visits(closest_distance, current_visits_rate)\n",
    "    closest_weighted_inf =compute_visits(closest_weighted, current_visits_rate)\n",
    "    example_2_partner_choice.append([top_cent_visits, top_w_cent_visits, random_visits, most_avg_visits_inf, closest_weighted_inf, closest_distance_inf])\n",
    "\n",
    "\n",
    "example_2_partner_choice = pd.DataFrame(example_2_partner_choice, columns = ['top_cent_visits', 'top_w_cent_visits', 'random_visits', 'most_avg_visits_inf', 'closest_weighted_inf', \"closest_distance_inf\"])\n",
    "example_2_partner_choice.mean()\n",
    "example_2_partner_choice['type'] = 'example_2_partner_choice'\n",
    "example_2_partner_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "DAY = 30 \n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "data = example_2_partner_choice\n",
    "data_sub = data.melt(value_vars = data.columns[:-1])\n",
    "data_sub['value'] = data_sub['value'].astype('float')\n",
    "\n",
    "data_sub['Increased visits'] = DAY * data_sub['value']#%/ 3200 * 100\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Increased visits')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(6), ['MIC', 'WIC', 'random', 'avg visits', 'weighted visits', 'closest'], fontsize = 12, rotation = 30, fontweight = 'bold')\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'visits.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_rage = [0.0203, 0.0603]#[0.1, 0.2]\n",
    "k = 1\n",
    "\n",
    "top_selected_w = neib_centrality_visits.sort_values('weighted_influence_exp', ascending =False)[:k]['Neib_Brand'].values\n",
    "top_selected = neib_centrality_visits.sort_values('influence_exp', ascending =False)[:k]['Neib_Brand'].values\n",
    "most_avg_visits = ranked_dic_visits_exp.sort_values('avg_visits', ascending =False).index[:k].values\n",
    "closest_distance = ranked_dic_visits_exp.sort_values('distance', ascending = True).index[:k].values\n",
    "closest_weighted = ranked_dic_visits_exp.sort_values('weighted_visits', ascending =False).index[:k].values\n",
    "\n",
    "example_2_partner_choice = []\n",
    "\n",
    "def compute_visits(selected, current_visits_rate):\n",
    "    sub_g = visits_all_business_pure_visits[visits_all_business_pure_visits.Neib_Brand.isin(list(selected))]    \n",
    "    return sub_g.num_inf_visits_exp.sum() * current_visits_rate\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    top_cent_visits = compute_visits(top_selected, current_visits_rate)\n",
    "    top_w_cent_visits = compute_visits(top_selected_w, current_visits_rate)\n",
    "    random_selected = random.choices(visits_all_business_pure_visits.Neib_Brand.unique(), k = k)\n",
    "    random_visits = compute_visits(random_selected, current_visits_rate)\n",
    "    most_avg_visits_inf = compute_visits(most_avg_visits, current_visits_rate)\n",
    "    closest_distance_inf = compute_visits(closest_distance, current_visits_rate)\n",
    "    closest_weighted_inf =compute_visits(closest_weighted, current_visits_rate)\n",
    "    example_2_partner_choice.append([top_cent_visits, top_w_cent_visits, random_visits, most_avg_visits_inf, closest_weighted_inf, closest_distance_inf])\n",
    "\n",
    "\n",
    "example_2_partner_choice = pd.DataFrame(example_2_partner_choice, columns = ['top_cent_visits', 'top_w_cent_visits', 'random_visits', 'most_avg_visits_inf', 'closest_weighted_inf', \"closest_distance_inf\"])\n",
    "example_2_partner_choice.mean()\n",
    "example_2_partner_choice['type'] = 'example_2_partner_choice'\n",
    "example_2_partner_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "DAY = 30 \n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "data = example_2_partner_choice\n",
    "data_sub = data.melt(value_vars = data.columns[:-1])\n",
    "data_sub['value'] = data_sub['value'].astype('float')\n",
    "\n",
    "data_sub['Increased visits'] = DAY * data_sub['value']#%/ 3200 * 100\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Increased visits')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(6), ['MIC', 'WIC', 'random', 'avg visits', 'weighted visits', 'closest'], fontsize = 12, rotation = 30, fontweight = 'bold')\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'visits_exp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4 Inbound Centrality Budget Allocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the folder to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join('example4_inbound_centrality_budget_allocations', brand)\n",
    "os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_rage = [0.0203, 0.0603] \n",
    "k = 5\n",
    "example_4_budget_allocation = []\n",
    "avg_visits = visits_all_business_pure_reviews.sort_values('Neib_avg_visits', ascending = False)[:k]\n",
    "weighted_visits = visits_all_business_pure_reviews.sort_values('weighted_visits', ascending = False)[:k]\n",
    "closest = visits_all_business_pure_reviews.sort_values('Time_mins_inv', ascending = True)[:k]\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    estimate_based =  visits_all_business_pure_reviews['num_inf_visits'][:k].sum() * current_visits_rate  #(df['num_inf_visits'][:k].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    random_based = np.sum(random.choices(visits_all_business_pure_reviews['num_inf_visits'].values, k = k)) * current_visits_rate #(np.sum(random.choices(df['num_inf_visits'].values, k = k)) * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    avg_visits_profit = np.sum(avg_visits['num_inf_visits']) * current_visits_rate #(avg_visits['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    weighted_visits_profit = np.sum(weighted_visits['num_inf_visits'])  * current_visits_rate #(weighted_visits['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    closest_profit = np.sum(closest['num_inf_visits']) * current_visits_rate  #(closest['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    example_4_budget_allocation.append([estimate_based, random_based, avg_visits_profit, weighted_visits_profit, closest_profit])\n",
    "\n",
    "\n",
    "example_4_budget_allocation = pd.DataFrame(example_4_budget_allocation, columns = ['top', 'random', 'avg_visits_profit', 'weighted_visits_profit', 'closest_profit'])\n",
    "example_4_budget_allocation['type'] = 'example_4_budget_allocation'\n",
    "example_4_budget_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "DAY = 30\n",
    "plt.figure(figsize = (8, 5))\n",
    "data = example_4_budget_allocation      \n",
    "data_sub = data.melt(value_vars = data.columns[:-1])    \n",
    "\n",
    "data_sub['Revenue'] = DAY * data_sub['value']\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Revenue')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(5), [ 'WIC+WIBC', 'random', 'average visits', 'weighted visits', 'closest'], fontsize = 12, fontweight = 'bold', rotation = 30)\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'reviews.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_rage = [0.0203, 0.0603] \n",
    "k = 5\n",
    "example_4_budget_allocation = []\n",
    "avg_visits = visits_all_business_pure_reviews.sort_values('Neib_avg_visits', ascending = False)[:k]\n",
    "weighted_visits = visits_all_business_pure_reviews.sort_values('weighted_visits', ascending = False)[:k]\n",
    "closest = visits_all_business_pure_reviews.sort_values('Time_mins_inv_exp', ascending = True)[:k]\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    estimate_based =  visits_all_business_pure_reviews['num_inf_visits_exp'][:k].sum() * current_visits_rate  #(df['num_inf_visits'][:k].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    random_based = np.sum(random.choices(visits_all_business_pure_reviews['num_inf_visits_exp'].values, k = k)) * current_visits_rate #(np.sum(random.choices(df['num_inf_visits'].values, k = k)) * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    avg_visits_profit = np.sum(avg_visits['num_inf_visits_exp']) * current_visits_rate #(avg_visits['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    weighted_visits_profit = np.sum(weighted_visits['num_inf_visits_exp'])  * current_visits_rate #(weighted_visits['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    closest_profit = np.sum(closest['num_inf_visits_exp']) * current_visits_rate  #(closest['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    example_4_budget_allocation.append([estimate_based, random_based, avg_visits_profit, weighted_visits_profit, closest_profit])\n",
    "\n",
    "\n",
    "example_4_budget_allocation = pd.DataFrame(example_4_budget_allocation, columns = ['top', 'random', 'avg_visits_profit', 'weighted_visits_profit', 'closest_profit'])\n",
    "example_4_budget_allocation['type'] = 'example_4_budget_allocation'\n",
    "example_4_budget_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "plt.figure(figsize = (8, 5))\n",
    "data = example_4_budget_allocation      \n",
    "data_sub = data.melt(value_vars = data.columns[:-1])    \n",
    "\n",
    "data_sub['Revenue'] = DAY * data_sub['value']\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Revenue')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(5), [ 'WIC+WIBC', 'random', 'average visits', 'weighted visits', 'closest'], fontsize = 12, fontweight = 'bold', rotation = 30)\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'reviews_exp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_all_business_pure_visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_rage = [0.0203, 0.0603]\n",
    "k = 5\n",
    "example_4_budget_allocation = []\n",
    "avg_visits = visits_all_business_pure_visits.sort_values('Neib_avg_visits', ascending = False)[:k]\n",
    "weighted_visits = visits_all_business_pure_visits.sort_values('weighted_visits', ascending = False)[:k]\n",
    "closest = visits_all_business_pure_visits.sort_values('Time_mins_inv', ascending = True)[:k]\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    estimate_based =  visits_all_business_pure_visits['num_inf_visits'][:k].sum() * current_visits_rate  #(df['num_inf_visits'][:k].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    random_based = np.sum(random.choices(visits_all_business_pure_visits['num_inf_visits'].values, k = k)) * current_visits_rate #(np.sum(random.choices(df['num_inf_visits'].values, k = k)) * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    avg_visits_profit = np.sum(avg_visits['num_inf_visits']) * current_visits_rate #(avg_visits['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    weighted_visits_profit = np.sum(weighted_visits['num_inf_visits'])  * current_visits_rate #(weighted_visits['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    closest_profit = np.sum(closest['num_inf_visits']) * current_visits_rate  #(closest['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    example_4_budget_allocation.append([estimate_based, random_based, avg_visits_profit, weighted_visits_profit, closest_profit])\n",
    "\n",
    "\n",
    "example_4_budget_allocation = pd.DataFrame(example_4_budget_allocation, columns = ['top', 'random', 'avg_visits_profit', 'weighted_visits_profit', 'closest_profit'])\n",
    "example_4_budget_allocation['type'] = 'example_4_budget_allocation'\n",
    "example_4_budget_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "plt.figure(figsize = (8, 5))\n",
    "data = example_4_budget_allocation      \n",
    "data_sub = data.melt(value_vars = data.columns[:-1])    \n",
    "\n",
    "data_sub['Revenue'] = DAY * data_sub['value']\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Revenue')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(5), [ 'WIC+WIBC', 'random', 'average visits', 'weighted visits', 'closest'], fontsize = 12, fontweight = 'bold', rotation = 30)\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'visits.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_rage = [0.0203, 0.0603]\n",
    "k = 5\n",
    "example_4_budget_allocation = []\n",
    "avg_visits = visits_all_business_pure_visits.sort_values('Neib_avg_visits', ascending = False)[:k]\n",
    "weighted_visits = visits_all_business_pure_visits.sort_values('weighted_visits', ascending = False)[:k]\n",
    "closest = visits_all_business_pure_visits.sort_values('Time_mins_inv_exp', ascending = True)[:k]\n",
    "\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    estimate_based =  visits_all_business_pure_visits['num_inf_visits_exp'][:k].sum() * current_visits_rate  #(df['num_inf_visits'][:k].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    random_based = np.sum(random.choices(visits_all_business_pure_visits['num_inf_visits_exp'].values, k = k)) * current_visits_rate #(np.sum(random.choices(df['num_inf_visits'].values, k = k)) * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    avg_visits_profit = np.sum(avg_visits['num_inf_visits_exp']) * current_visits_rate #(avg_visits['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    weighted_visits_profit = np.sum(weighted_visits['num_inf_visits_exp'])  * current_visits_rate #(weighted_visits['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    closest_profit = np.sum(closest['num_inf_visits_exp']) * current_visits_rate  #(closest['num_inf_visits'].sum() * current_visits_rate * consumer_spending - k * budget ) / k * budget  * 100 \n",
    "    example_4_budget_allocation.append([estimate_based, random_based, avg_visits_profit, weighted_visits_profit, closest_profit])\n",
    "\n",
    "\n",
    "example_4_budget_allocation = pd.DataFrame(example_4_budget_allocation, columns = ['top', 'random', 'avg_visits_profit', 'weighted_visits_profit', 'closest_profit'])\n",
    "example_4_budget_allocation['type'] = 'example_4_budget_allocation'\n",
    "example_4_budget_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "plt.figure(figsize = (8, 5))\n",
    "data = example_4_budget_allocation\n",
    "data_sub = data.melt(value_vars = data.columns[:-1])    \n",
    "\n",
    "data_sub['Revenue'] = DAY * data_sub['value']\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Revenue')\n",
    "plt.title('{}'.format(brand), fontsize = 12, fontweight = 'bold')\n",
    "plt.xticks(range(5), [ 'WIC+WIBC', 'random', 'average visits', 'weighted visits', 'closest'], fontsize = 12, fontweight = 'bold', rotation = 30)\n",
    "plt.xlabel('')\n",
    "plt.yticks(fontsize = 12, fontweight = 'bold')\n",
    "plt.ylabel('Increased visits', fontsize = 12, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(dir_path, 'visits_exp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Inbound Centrality for Local Marketing Partnerships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_store_chosen_num = 1\n",
    "#%%\n",
    "# https://coresight.com/research/going-head-to-head-in-beauty-retailing-a-comparison-of-sephora-and-ulta/\n",
    "ranked_dic = visits_all_business_pure.groupby('Focal_Stores').agg(num_neighbors=('Neib_Stores', 'count'),\n",
    "                                                   focal_avg_visits=('Foc_avg_visits', 'mean'),\n",
    "                                                   neighbor_avg_visits=('Neib_avg_visits', 'sum'),\n",
    "                                                   weighted_visits = ('weighted_visits', 'sum')\n",
    "                                                )\n",
    "\n",
    "#%%\n",
    "\n",
    "top_selected_w = inner_centrality.sort_values('weighted_influence', ascending =False)[:focal_store_chosen_num].Focal_Stores.values\n",
    "top_selected = inner_centrality.sort_values('influence', ascending =False)[:focal_store_chosen_num].Focal_Stores.values\n",
    "num_stores = ranked_dic.sort_values('num_neighbors', ascending =False).index[:focal_store_chosen_num]\n",
    "focal_avg_visits = ranked_dic.sort_values('focal_avg_visits', ascending =False).index[:focal_store_chosen_num]\n",
    "avg_visits = ranked_dic.sort_values('neighbor_avg_visits', ascending =False).index[:focal_store_chosen_num]\n",
    "weighted_visits = ranked_dic.sort_values('weighted_visits', ascending =False).index[:focal_store_chosen_num]\n",
    "\n",
    "\n",
    "def compute_visits_eg3(store_id, current_visits_rate, num_neighboring_store = 3):\n",
    "    sub_g = visits_all_business_pure[visits_all_business_pure.Focal_Stores.isin(store_id)]\n",
    "    #sub_g = sub_g.sort_values('weighted_visits', ascending = False).reset_index()#[:num_neighboring_store]\n",
    "    visits = 0 \n",
    "    for i in range(sub_g.shape[0]):\n",
    "        visits += sub_g['num_inf_visits'].values[i] \n",
    "    return visits * current_visits_rate\n",
    "\n",
    "\n",
    "### a single collaborator store \n",
    "example_3_local_partner_choice = []\n",
    "for rand in range(100):\n",
    "    current_visits_rate = random.uniform(visits_rage[0], visits_rage[1]) \n",
    "    random_selected = random.choice(ranked_dic.index)\n",
    "    rand_profit = compute_visits_eg3([random_selected], current_visits_rate)\n",
    "    top_selected_w_profit = compute_visits_eg3(top_selected_w, current_visits_rate)\n",
    "    top_selected_profit = compute_visits_eg3(top_selected, current_visits_rate)\n",
    "    num_stores_profit = compute_visits_eg3(num_stores, current_visits_rate)\n",
    "    focal_avg_visits_profit = compute_visits_eg3(focal_avg_visits, current_visits_rate)\n",
    "    avg_visits_prift = compute_visits_eg3(avg_visits, current_visits_rate)\n",
    "    closest_weighted_profit = compute_visits_eg3(weighted_visits, current_visits_rate)\n",
    "    example_3_local_partner_choice.append([rand_profit, top_selected_profit, top_selected_w_profit,  num_stores_profit, focal_avg_visits_profit, avg_visits_prift, closest_weighted_profit])\n",
    "\n",
    "\n",
    "example_3_local_partner_choice = pd.DataFrame( example_3_local_partner_choice , columns =['rand_profit', 'top_selected_profit', 'top_selected_w_profit', 'num_stores_profit', 'focal_avg_visits_profit', \"avg_visits_prift\", \"closest_weighted_profit\"])\n",
    "example_3_local_partner_choice['type'] = 'example_3_local_partner_choice'\n",
    "\n",
    "example_3_local_partner_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0 \n",
    "plt.figure(figsize = (32, 8))\n",
    "data = example_3_local_partner_choice\n",
    "data_sub = data.melt(value_vars = data.columns[:-1])\n",
    "plt.subplot(131 + cnt)\n",
    "cnt += 1 \n",
    "data_sub['Revenue'] = DAY * (data_sub['value']) #/ 4000 * 100\n",
    "\n",
    "order = ['top_selected_profit', 'top_selected_w_profit', 'rand_profit', 'num_stores_profit', \n",
    "            'focal_avg_visits_profit',  'closest_weighted_profit']\n",
    "sns.barplot(data = data_sub, x = 'variable', y = 'Revenue', order=order)\n",
    "plt.title('{}'.format(brand), fontsize = 20, fontweight = 'bold')\n",
    "plt.yticks(fontsize = 20, fontweight = 'bold')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Increased visits', fontsize = 20, fontweight = 'bold')\n",
    "plt.xticks(range(6), [ 'MIBC', 'WIBC', 'random', '# neighbors', 'focal visits', 'neighbor visits'], fontsize = 20, fontweight = 'bold', rotation = 30)\n",
    "#plt.suptitle('Local marketing partnership for five neighbors of a chosen focal store', fontsize = 20, fontweight = 'bold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the Figure D1 and D2\n",
    "\n",
    "1. Then we need to plot their X_Estimate for each of the four models\n",
    "2. Then we need to put stars at the neighboring brands as per the p-value for each model \\\n",
    "-> *** means p_value <= 0.01 \\\n",
    "-> ** means 0.01 < p_value <= 0.05 \\\n",
    "-> * means 0.05 < p_value <= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pvalue_stars(p_value):\n",
    "    if p_value <= 0.01:\n",
    "        return '***'\n",
    "    elif 0.01 < p_value <= 0.05:\n",
    "        return '**'\n",
    "    elif 0.05 < p_value <= 0.1:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_est_df = result_df[result_df['filename'].isin(significant_brands_list)]\n",
    "coeff_est_df['X_pvalue_stars'] = coeff_est_df['X_Pr(>|t|)'].apply(get_pvalue_stars)\n",
    "coeff_est_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reviews = coeff_est_df[coeff_est_df['type'] == 'fe_reviews_reviews'].sort_values('X_Estimate', ascending=False)\n",
    "lin_visits = coeff_est_df[coeff_est_df['type'] == 'fe_reviews_visits'].sort_values('X_Estimate', ascending=False)\n",
    "exp_reviews = coeff_est_df[coeff_est_df['type'] == 'fe_exp_reviews_reviews'].sort_values('X_Estimate', ascending=False)\n",
    "exp_visits = coeff_est_df[coeff_est_df['type'] == 'fe_exp_reviews_visits'].sort_values('X_Estimate', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_first_stage_results_review(row):\n",
    "    # Twitter Vaues\n",
    "    tw_estimate = format(float(row['IV_firststage_reviews_tw_Estimate']), '.2e')\n",
    "    tw_std_err = format(float(row['IV_firststage_reviews_tw_Std. Error']), '.2e')\n",
    "    tw_p_value = float(row['IV_firststage_reviews_tw_Pr(>|t|)'])\n",
    "    \n",
    "    # Facebook Vaues\n",
    "    fb_estimate = format(float(row['IV_firststage_reviews_fb_Estimate']), '.2e')\n",
    "    fb_std_err = format(float(row['IV_firststage_reviews_fb_Std. Error']), '.2e')\n",
    "    fb_p_value = float(row['IV_firststage_reviews_fb_Pr(>|t|)'])\n",
    "    \n",
    "    # Instagram Vaues\n",
    "    ig_estimate = format(float(row['IV_firststage_reviews_ig_Estimate']), '.2e')\n",
    "    ig_std_err = format(float(row['IV_firststage_reviews_ig_Std. Error']), '.2e')\n",
    "    ig_p_value = float(row['IV_firststage_reviews_ig_Pr(>|t|)'])\n",
    "    \n",
    "    # Getting table entries\n",
    "    twitter_likes = str(tw_estimate) + get_pvalue_stars(tw_p_value) + \"({})\".format(tw_std_err)\n",
    "    facebook_likes = str(fb_estimate) + get_pvalue_stars(fb_p_value) + \"({})\".format(fb_std_err)\n",
    "    instagram_likes = str(ig_estimate) + get_pvalue_stars(ig_p_value) + \"({})\".format(ig_std_err)\n",
    "    \n",
    "    # Calculating significant variables\n",
    "    num_sig = 0\n",
    "    \n",
    "    if (tw_p_value <= 0.05):\n",
    "        num_sig += 1\n",
    "\n",
    "    if (fb_p_value <= 0.05):\n",
    "        num_sig += 1\n",
    "\n",
    "    if (ig_p_value <= 0.05):\n",
    "        num_sig += 1\n",
    "    \n",
    "    # Getting WaldTest F-Stats\n",
    "    wald_f_stat = row['WaldTest_F']\n",
    "        \n",
    "    return pd.Series([twitter_likes, facebook_likes, instagram_likes, num_sig, wald_f_stat],\n",
    "                     index=['Twitter Likes', 'Facebook Likes', 'Instagram Likes', 'Num Sig', 'Weka Instrument (F-stats)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_first_stage_results_visits(row):\n",
    "    # Visits Vaues\n",
    "    visits_estimate = format(float(row['IV_firststage_visits_Estimate']), '.2e')\n",
    "    visits_std_err = format(float(row['IV_firststage_visits_Std. Error']), '.2e')\n",
    "    visits_p_value = float(row['IV_firststage_visits_Pr(>|t|)'])\n",
    "        \n",
    "    # Getting table entries\n",
    "    visits = str(visits_estimate) + get_pvalue_stars(visits_p_value) + \"({})\".format(visits_std_err)\n",
    "        \n",
    "    # Getting WaldTest F-Stats\n",
    "    wald_f_stat = row['WaldTest_F']\n",
    "        \n",
    "    return pd.Series([visits, wald_f_stat],\n",
    "                     index=['Visits', 'Weka Instrument (F-stats)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stage_linear_reviews = lin_reviews.apply(prepare_first_stage_results_review, axis=1, result_type='expand').reset_index(drop=True)\n",
    "first_stage_linear_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stage_linear_visits = lin_visits.apply(prepare_first_stage_results_visits, axis=1, result_type='expand').reset_index(drop=True)\n",
    "first_stage_linear_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stage_exp_reviews = exp_reviews.apply(prepare_first_stage_results_review, axis=1, result_type='expand').reset_index(drop=True)\n",
    "first_stage_exp_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stage_exp_visits = exp_visits.apply(prepare_first_stage_results_visits, axis=1, result_type='expand').reset_index(drop=True)\n",
    "first_stage_exp_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_colors = {\n",
    "    'positive': '#6488ea',  # Blue for positive estimates\n",
    "    'star': '#922b05',  # Red for negative estimates\n",
    "    'negative': '#3d9973'       # Prettier yellow for stars\n",
    "}\n",
    "\n",
    "confidence_level = 0.95\n",
    "lin_reviews['Lower Bound'] = lin_reviews['X_Estimate'] - 1.96 * lin_reviews['X_Std. Error']\n",
    "lin_reviews['Upper Bound'] = lin_reviews['X_Estimate'] + 1.96 * lin_reviews['X_Std. Error']\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# Add a constant offset for stars\n",
    "star_offset = 0.1\n",
    "    \n",
    "# Set the font size for the stars\n",
    "star_fontsize = 15\n",
    "\n",
    "# Plotting estimates and confidence intervals for each business\n",
    "for idx, row in lin_reviews.iterrows():\n",
    "    biz_biz = row['filename']\n",
    "    estimate = row['X_Estimate']\n",
    "    std_error = row['X_Std. Error']\n",
    "    lower_bound = row['Lower Bound']\n",
    "    upper_bound = row['Upper Bound']\n",
    "\n",
    "    # Determine the color based on the sign of the estimate\n",
    "    color = custom_colors['positive'] if estimate >= 0 else custom_colors['negative']\n",
    "\n",
    "    # Plotting the bars with different colors for positive and negative estimates\n",
    "    ax.barh(biz_biz, estimate, xerr=[[estimate - lower_bound], [upper_bound - estimate]], color=color)\n",
    "\n",
    "    # Add stars based on the number of *s in the \"coefficients\" column with an offset\n",
    "    stars = row['X_pvalue_stars'].count('*')\n",
    "    if stars > 0:\n",
    "        # Set the alignment for negative estimates\n",
    "        ha = 'left' if estimate >= 0 else 'right'\n",
    "        ax.text(estimate + star_offset if estimate >= 0 else estimate - star_offset, biz_biz, '*' * stars, va='center', ha=ha, color=custom_colors['star'], fontsize=star_fontsize)\n",
    "\n",
    "plt.axvline(x=0, linestyle='--', color='gray')  # Plotting a dashed line for the estimate\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Estimate')\n",
    "ax.set_title('Linear Reviews')\n",
    "ax.set_xscale('symlog')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_colors = {\n",
    "    'positive': '#6488ea',  # Blue for positive estimates\n",
    "    'star': '#922b05',  # Red for negative estimates\n",
    "    'negative': '#3d9973'       # Prettier yellow for stars\n",
    "}\n",
    "\n",
    "confidence_level = 0.95\n",
    "lin_visits['Lower Bound'] = lin_visits['X_Estimate'] - 1.96 * lin_visits['X_Std. Error']\n",
    "lin_visits['Upper Bound'] = lin_visits['X_Estimate'] + 1.96 * lin_visits['X_Std. Error']\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# Add a constant offset for stars\n",
    "star_offset = 0.1\n",
    "    \n",
    "# Set the font size for the stars\n",
    "star_fontsize = 15\n",
    "\n",
    "# Plotting estimates and confidence intervals for each business\n",
    "for idx, row in lin_visits.iterrows():\n",
    "    biz_biz = row['filename']\n",
    "    estimate = row['X_Estimate']\n",
    "    std_error = row['X_Std. Error']\n",
    "    lower_bound = row['Lower Bound']\n",
    "    upper_bound = row['Upper Bound']\n",
    "\n",
    "    # Determine the color based on the sign of the estimate\n",
    "    color = custom_colors['positive'] if estimate >= 0 else custom_colors['negative']\n",
    "\n",
    "    # Plotting the bars with different colors for positive and negative estimates\n",
    "    ax.barh(biz_biz, estimate, xerr=[[estimate - lower_bound], [upper_bound - estimate]], color=color)\n",
    "\n",
    "    # Add stars based on the number of *s in the \"coefficients\" column with an offset\n",
    "    stars = row['X_pvalue_stars'].count('*')\n",
    "    if stars > 0:\n",
    "        # Set the alignment for negative estimates\n",
    "        ha = 'left' if estimate >= 0 else 'right'\n",
    "        ax.text(estimate + star_offset if estimate >= 0 else estimate - star_offset, biz_biz, '*' * stars, va='center', ha=ha, color=custom_colors['star'], fontsize=star_fontsize)\n",
    "\n",
    "plt.axvline(x=0, linestyle='--', color='gray')  # Plotting a dashed line for the estimate\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Estimate')\n",
    "ax.set_title('Linear Visits')\n",
    "ax.set_xscale('symlog')\n",
    "ax.set_xlim()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_colors = {\n",
    "    'positive': '#6488ea',  # Blue for positive estimates\n",
    "    'star': '#922b05',  # Red for negative estimates\n",
    "    'negative': '#3d9973'       # Prettier yellow for stars\n",
    "}\n",
    "\n",
    "confidence_level = 0.95\n",
    "exp_reviews['Lower Bound'] = exp_reviews['X_Estimate'] - 1.96 * exp_reviews['X_Std. Error']\n",
    "exp_reviews['Upper Bound'] = exp_reviews['X_Estimate'] + 1.96 * exp_reviews['X_Std. Error']\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# Add a constant offset for stars\n",
    "star_offset = 0.1\n",
    "    \n",
    "# Set the font size for the stars\n",
    "star_fontsize = 15\n",
    "\n",
    "# Plotting estimates and confidence intervals for each business\n",
    "for idx, row in exp_reviews.iterrows():\n",
    "    biz_biz = row['filename']\n",
    "    estimate = row['X_Estimate']\n",
    "    std_error = row['X_Std. Error']\n",
    "    lower_bound = row['Lower Bound']\n",
    "    upper_bound = row['Upper Bound']\n",
    "\n",
    "    # Determine the color based on the sign of the estimate\n",
    "    color = custom_colors['positive'] if estimate >= 0 else custom_colors['negative']\n",
    "\n",
    "    # Plotting the bars with different colors for positive and negative estimates\n",
    "    ax.barh(biz_biz, estimate, xerr=[[estimate - lower_bound], [upper_bound - estimate]], color=color)\n",
    "\n",
    "    # Add stars based on the number of *s in the \"coefficients\" column with an offset\n",
    "    stars = row['X_pvalue_stars'].count('*')\n",
    "    if stars > 0:\n",
    "        # Set the alignment for negative estimates\n",
    "        ha = 'left' if estimate >= 0 else 'right'\n",
    "        ax.text(estimate + star_offset if estimate >= 0 else estimate - star_offset, biz_biz, '*' * stars, va='center', ha=ha, color=custom_colors['star'], fontsize=star_fontsize)\n",
    "\n",
    "plt.axvline(x=0, linestyle='--', color='gray')  # Plotting a dashed line for the estimate\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Estimate')\n",
    "ax.set_title('Exponential Reviews')\n",
    "ax.set_xscale('symlog')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_colors = {\n",
    "    'positive': '#6488ea',  # Blue for positive estimates\n",
    "    'star': '#922b05',  # Red for negative estimates\n",
    "    'negative': '#3d9973'       # Prettier yellow for stars\n",
    "}\n",
    "\n",
    "confidence_level = 0.95\n",
    "exp_visits['Lower Bound'] = exp_visits['X_Estimate'] - 1.96 * exp_visits['X_Std. Error']\n",
    "exp_visits['Upper Bound'] = exp_visits['X_Estimate'] + 1.96 * exp_visits['X_Std. Error']\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# Add a constant offset for stars\n",
    "star_offset = 0.1\n",
    "    \n",
    "# Set the font size for the stars\n",
    "star_fontsize = 15\n",
    "\n",
    "# Plotting estimates and confidence intervals for each business\n",
    "for idx, row in exp_visits.iterrows():\n",
    "    biz_biz = row['filename']\n",
    "    estimate = row['X_Estimate']\n",
    "    std_error = row['X_Std. Error']\n",
    "    lower_bound = row['Lower Bound']\n",
    "    upper_bound = row['Upper Bound']\n",
    "\n",
    "    # Determine the color based on the sign of the estimate\n",
    "    color = custom_colors['positive'] if estimate >= 0 else custom_colors['negative']\n",
    "\n",
    "    # Plotting the bars with different colors for positive and negative estimates\n",
    "    ax.barh(biz_biz, estimate, xerr=[[estimate - lower_bound], [upper_bound - estimate]], color=color)\n",
    "\n",
    "    # Add stars based on the number of *s in the \"coefficients\" column with an offset\n",
    "    stars = row['X_pvalue_stars'].count('*')\n",
    "    if stars > 0:\n",
    "        # Set the alignment for negative estimates\n",
    "        ha = 'left' if estimate >= 0 else 'right'\n",
    "        ax.text(estimate + star_offset if estimate >= 0 else estimate - star_offset, biz_biz, '*' * stars, va='center', ha=ha, color=custom_colors['star'], fontsize=star_fontsize)\n",
    "\n",
    "plt.axvline(x=0, linestyle='--', color='gray')  # Plotting a dashed line for the estimate\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Estimate')\n",
    "ax.set_title('Exponential Visits')\n",
    "ax.set_xscale('symlog')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "business-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
